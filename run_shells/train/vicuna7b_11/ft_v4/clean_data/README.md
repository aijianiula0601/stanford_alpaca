# 说明


针对ft线上bigolive数据，出现的体验问题清洗数据，这里主要按照第二个解决方案清洗数据。



# 问题分析记录 

对于vicuna7b中的ft线上bigolive数据的模型出现的问题分析总结

## 问题：

-   回复太长

-   连续反问

-   后尾出现:)这个笑脸符号概率大问题


###原因分析：

-   回复过长问题
    
查看训练数据，线上bigolive回复，有些的确较长，可能模型过拟合了这种长回复。
通过在prompt中加入“Keep your responses short. Don't ask multiple questions at once.”，貌似回复简短了些，由于有一定概率性，无法完全确定是否真的变短，因为有时候不加，也回复不长。


-   连续反问问题


查看训练数据，线上bigolive某些回复，的确有连续反问，但是出现的概率貌似没有我们模型那么频繁，推测模型过拟合一些连续反问的回复。


-   后尾出现:)这个笑脸符号概率大问题 
    
通过grep在bigolive数据中看到很多回复有:)这个笑脸问题，而multitype数据中有但很少。

###解决的实验方案：

目前主要分析了训练数据，推测很大可能是模型对训练数据拟合过充分了。

-   第一步解决方案：

重新训练模型，只训练一个opoch，让模型学回答风格，不过分训练。

-   第二步解决方案：

    -   修正训练数据
    -   程序剔除一些回复过长的回复。
    -   程序删除 :) 笑脸